# Artificial Intelligence have the risk in leaking personal information
In this assignment, I discuss two articles about the personal pravicy in AI.

## Article 1: 
In the artical [New study shows large language models have high toxic probabilities and leak private information](https://techxplore.com/news/2023-08-large-language-high-toxic-probabilities.html), it talks about the risk of the personal information leaking and the potential risk of the high toxic probabilities. After reading this artical, I think artificial intelligence is a double-edged sword. It can help us to do a lot of things, but it also has a lot of risks. We cannot believe it completely. We need to be careful when using it and for every result it gives, we need to think about it by ourselves as well.

And especially for large language models, it is more likely to leak personal information. Because when we use it, we need to give it a lot of information, and it will use these information to give us the result. We cannot determine how it use these data, so we need to have a clear understanding of the risk of using it.

## Article 2:
In the artical [Rules to keep AI in check: nations carve different paths for tech regulation](https://www.nature.com/articles/d41586-023-02491-y), it talks about solutions about avoiding the risk of AI. With a rapid development of our society and the technology, some institutions and countries have already set up different rules to keep AI in check. And also, there exists some rules for technology to follow. 

In my opinion, these solutions are helpful for people to use AI. Because with these rules, we can avoid some risks of AI, such as the abuse of personal information and auto data collection. So that we can use AI more safely. But there are still some problems. For example, some rules are not strict enough, and some rules are not clear enough. So, we need to improve these rules to make them more useful.